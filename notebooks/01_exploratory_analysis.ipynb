{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aircraft Predictive Maintenance - Exploratory Data Analysis\n",
    "\n",
    "This notebook explores the NASA Turbofan Engine Degradation Simulation Dataset to understand the data characteristics and prepare for model development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import stats\n",
    "\n",
    "# Add the src directory to the path to import custom modules\n",
    "sys.path.append('..')\n",
    "from src.data_processing import load_data, clean_data, calculate_rul\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "\n",
    "# Configure pandas display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Dataset\n",
    "\n",
    "The NASA Turbofan Engine Degradation Simulation Dataset consists of multiple files. We'll start with the FD001 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column names for the dataset\n",
    "NASA_COLUMNS = [\n",
    "    'engine_id', 'cycle', \n",
    "    'setting1', 'setting2', 'setting3', \n",
    "    's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', \n",
    "    's11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's20', 's21'\n",
    "]\n",
    "\n",
    "# Load the dataset\n",
    "data_path = '../data/raw/train_FD001.txt'\n",
    "if os.path.exists(data_path):\n",
    "    data = load_data(data_path)\n",
    "    print(f\"Dataset loaded with shape: {data.shape}\")\n",
    "else:\n",
    "    print(f\"Dataset not found at {data_path}\")\n",
    "    print(\"Please download the NASA Turbofan Engine Degradation Simulation Dataset from Kaggle:\")\n",
    "    print(\"https://www.kaggle.com/datasets/behrad3d/nasa-cmaps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Overview\n",
    "\n",
    "Let's examine the basic statistics and structure of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_values[missing_values > 0] if missing_values.sum() > 0 else \"No missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique engines\n",
    "n_engines = data['engine_id'].nunique()\n",
    "print(f\"Number of unique engines: {n_engines}\")\n",
    "\n",
    "# Distribution of cycles per engine\n",
    "cycles_per_engine = data.groupby('engine_id')['cycle'].max()\n",
    "print(f\"\\nCycles per engine statistics:\")\n",
    "print(cycles_per_engine.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate Remaining Useful Life (RUL)\n",
    "\n",
    "For predictive maintenance, we need to calculate the Remaining Useful Life (RUL) for each engine at each cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "cleaned_data = clean_data(data)\n",
    "\n",
    "# Calculate RUL\n",
    "rul_data = calculate_rul(cleaned_data)\n",
    "\n",
    "# Display the first few rows with RUL\n",
    "rul_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot RUL distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(rul_data['RUL'], kde=True, bins=30)\n",
    "plt.title('Distribution of Remaining Useful Life (RUL)')\n",
    "plt.xlabel('RUL (cycles)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize RUL Degradation\n",
    "\n",
    "Let's visualize how RUL decreases over time for a sample of engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a few engines for visualization\n",
    "sample_engines = np.random.choice(rul_data['engine_id'].unique(), 5, replace=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for engine_id in sample_engines:\n",
    "    engine_data = rul_data[rul_data['engine_id'] == engine_id]\n",
    "    plt.plot(engine_data['cycle'], engine_data['RUL'], marker='o', linestyle='-', label=f'Engine {engine_id}')\n",
    "\n",
    "plt.title('RUL Degradation Over Time for Sample Engines')\n",
    "plt.xlabel('Cycle')\n",
    "plt.ylabel('Remaining Useful Life (cycles)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sensor Analysis\n",
    "\n",
    "Let's analyze the sensor readings to understand their behavior and relationship with RUL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select sensor columns\n",
    "sensor_cols = [col for col in rul_data.columns if col.startswith('s')]\n",
    "\n",
    "# Correlation with RUL\n",
    "correlations = rul_data[sensor_cols + ['RUL']].corr()['RUL'].sort_values()\n",
    "\n",
    "# Plot correlation with RUL\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlations.drop('RUL').plot(kind='bar')\n",
    "plt.title('Sensor Correlation with RUL')\n",
    "plt.xlabel('Sensor')\n",
    "plt.ylabel('Correlation Coefficient')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Print top correlated sensors\n",
    "print(\"Top 5 positively correlated sensors:\")\n",
    "print(correlations.drop('RUL').nlargest(5))\n",
    "print(\"\\nTop 5 negatively correlated sensors:\")\n",
    "print(correlations.drop('RUL').nsmallest(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "plt.figure(figsize=(16, 12))\n",
    "correlation_matrix = rul_data[sensor_cols + ['RUL']].corr()\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=False, cmap='coolwarm', \n",
    "            linewidths=0.5, vmin=-1, vmax=1)\n",
    "plt.title('Correlation Heatmap of Sensors and RUL')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sensor Trends Over Time\n",
    "\n",
    "Let's visualize how sensor readings change over time for a sample engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a sample engine\n",
    "sample_engine_id = sample_engines[0]\n",
    "sample_engine_data = rul_data[rul_data['engine_id'] == sample_engine_id].sort_values('cycle')\n",
    "\n",
    "# Select top correlated sensors (both positive and negative)\n",
    "top_sensors = list(correlations.drop('RUL').abs().nlargest(6).index)\n",
    "\n",
    "# Plot sensor readings over time\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "for sensor in top_sensors:\n",
    "    plt.plot(sample_engine_data['cycle'], sample_engine_data[sensor], marker='.', \n",
    "             linestyle='-', label=sensor)\n",
    "\n",
    "plt.title(f'Top Correlated Sensor Readings Over Time for Engine {sample_engine_id}')\n",
    "plt.xlabel('Cycle')\n",
    "plt.ylabel('Sensor Value')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Operational Settings Analysis\n",
    "\n",
    "Let's analyze the operational settings and their impact on engine degradation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select operational setting columns\n",
    "setting_cols = [col for col in rul_data.columns if col.startswith('setting')]\n",
    "\n",
    "# Distribution of operational settings\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for i, col in enumerate(setting_cols):\n",
    "    sns.histplot(rul_data[col], kde=True, ax=axes[i])\n",
    "    axes[i].set_title(f'Distribution of {col}')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship between operational settings and RUL\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for i, col in enumerate(setting_cols):\n",
    "    sns.scatterplot(x=col, y='RUL', data=rul_data, alpha=0.5, ax=axes[i])\n",
    "    axes[i].set_title(f'RUL vs {col}')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Selection\n",
    "\n",
    "Based on our analysis, let's identify the most important features for predicting RUL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate absolute correlation with RUL\n",
    "abs_corr = correlations.drop('RUL').abs().sort_values(ascending=False)\n",
    "\n",
    "# Select top features based on correlation\n",
    "top_features = list(abs_corr.nlargest(10).index)\n",
    "\n",
    "print(\"Top 10 features based on correlation with RUL:\")\n",
    "for i, feature in enumerate(top_features, 1):\n",
    "    print(f\"{i}. {feature}: {correlations[feature]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the relationship between top features and RUL\n",
    "top_6_features = top_features[:6]\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(top_6_features):\n",
    "    sns.scatterplot(x=feature, y='RUL', data=rul_data, alpha=0.5, ax=axes[i])\n",
    "    axes[i].set_title(f'RUL vs {feature}')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Data Preparation for Modeling\n",
    "\n",
    "Let's prepare the data for modeling by normalizing features and creating sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "# Select features for normalization (all except engine_id, cycle, and RUL)\n",
    "features_to_normalize = [col for col in rul_data.columns \n",
    "                         if col not in ['engine_id', 'cycle', 'RUL']]\n",
    "\n",
    "# Initialize scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Create a copy of the data\n",
    "normalized_data = rul_data.copy()\n",
    "\n",
    "# Fit and transform the selected features\n",
    "normalized_data[features_to_normalize] = scaler.fit_transform(normalized_data[features_to_normalize])\n",
    "\n",
    "# Display the first few rows of normalized data\n",
    "normalized_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample sequence for visualization\n",
    "sequence_length = 30\n",
    "sample_engine_id = sample_engines[0]\n",
    "sample_engine_data = normalized_data[normalized_data['engine_id'] == sample_engine_id].sort_values('cycle')\n",
    "\n",
    "# Select a subset of features for visualization\n",
    "features_to_plot = top_6_features\n",
    "\n",
    "# Create a sequence\n",
    "start_idx = 50  # Start from cycle 50 for better visualization\n",
    "sequence_data = sample_engine_data.iloc[start_idx:start_idx+sequence_length]\n",
    "\n",
    "# Plot the sequence\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "for feature in features_to_plot:\n",
    "    plt.plot(sequence_data['cycle'], sequence_data[feature], marker='o', linestyle='-', label=feature)\n",
    "\n",
    "plt.title(f'Sample Sequence for Engine {sample_engine_id} (Cycles {start_idx+1} to {start_idx+sequence_length})')\n",
    "plt.xlabel('Cycle')\n",
    "plt.ylabel('Normalized Feature Value')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Next Steps\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. The dataset contains sensor readings from multiple engines over their operational cycles.\n",
    "2. We calculated the Remaining Useful Life (RUL) for each engine at each cycle.\n",
    "3. We identified the sensors that have the strongest correlation with RUL.\n",
    "4. We normalized the data and prepared it for sequence-based modeling.\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Create sequences for time series modeling.\n",
    "2. Split the data into training, validation, and test sets.\n",
    "3. Develop and train predictive models (LSTM, CNN-LSTM, XGBoost, etc.).\n",
    "4. Evaluate and compare model performance.\n",
    "5. Fine-tune the best performing model.\n",
    "\n",
    "These steps will be covered in the next notebook: `02_model_development.ipynb`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}